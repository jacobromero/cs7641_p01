\documentclass[
	%a4paper, % Use A4 paper size
	letterpaper, % Use US letter paper size
]{IEEEtran}


\author{Jacob Romero}
\title{Project 1: Supervised learning}

\begin{document}
	%\lsstyle
	\maketitle
	
	\begin{abstract}
		Machine learning has become more pervasive in our everyday life, used for everything from personalized advertising to making financial decisions. In this paper I will compare multiple machine learning algorithms against two datasets, both related to predicting financial information from individuals data. These comparisons will look at how each of the machines learning algorithms performs as more training data is introduced, how each algorithms performs as a function of training time, and lastly a comparison of the algorithms against each other.
	\end{abstract}
	
	\section{Introduction and Problems}
	In this paper I will look at two datasets, and compare these data sets to five different machine learning algorithms. These five algorithms are decision trees, neural networks, boosted decision trees, support vector machines, and k-nearest neighbors. Each algorithm has different properties in the sense of how it models a problem space, its preference bias, expression bias, how fast training and prediction can be done.
	
	\subsection{Dataset 1}
	The algorithms described previously will be ran and tested against two datasets. The first data set is data from the U.S. census regarding various attributes of an individual. The dataset has already been split into two files, a training set, and a testing set. The training set is composed of 32,561 instances, while the testing set has 16,281. Both sets have 14 attributes, these attributes include areas such as age, education level, marital status, occupation, race, sex, etc. From these attributes the final target is whether the individual makes less than or equal to 50 thousand dollars a year, or more than this amount. With a model that can accurately predict an individuals income, or income class in our case would have many uses in other areas, such as targeted marketing, personalized ads, or credit decisions. In addition this problem has some interesting facets to explore, such as what features of this dataset contributes to income.
	
	\subsubsection{Feature engineering}
	For this dataset the features were pretty clean, as such not much engineering was needed to get to a state where we can input the data into the machine learning algorithms for training. The only pre-processing I did was to convert the discrete columns into one hot encoded features. Allowing our data to be trained on by each of the models. 
	
	\subsection{Dataset 2}
	Continuing along the same thing of using machine learning for financial motivations, the second dataset again focuses on individuals, but from the other end of the spectrum, in which a customer either defaults on a loan or not. This dataset is made up of 24 attributes and is composed of 30,000 instances. Attributes of the dataset Include sex, age, marriage status, bill amount for 6 months, payment amount in those 6 months, and the status of the payment during those six months (i.e. paid on time, paid late and by how long, etc.). This again is an interesting problem because the sooner a model can predict possible defaults based, the better chance a lender has of helping the borrower to come to a mutually beneficial arrangement.
	
	\subsubsection{Feature engineering}
	For the second dataset, this contained more 'dirty' data and required more pre-processing than was done in dataset 1. In addition to the normal one hot encoding of categorical features as was done similarly. This data set had some undefined features in the education level, and marriage features which were denoted with \emph{'?'}, when an unknown bin had already been created. Because the number of instances where these occurred was 14 for the education case, and 54 for in the marriage case for a total of 68 instances with bad data these instances can just be dropped from the data as they only account for 0.2\% of the total data.
	
	Additionally after playing around with training on basic models with default parameters I discovered that, the sex, marriage status, and credit limit balance did not have any affect on the find out come of all of the models. In fact because these features increased the dimensionality of the data it caused decreased performance.
	
	\section{Experiments}
	For this project I was tasked with evaluating and comparing multiple algorithms listed above. Therefore I will train each of the algorithms on each dataset also mentioned above, I will evaluate the results of how each algorithm does as a function of training data comparing both the testing, and training data scores. In addition to this, I will compare how two algorithm's performance is affected as hyper-parameters are changed. Specifically I will look at how the max-depth parameter in decision trees, and the number of neighbors used in the K-nearest neighbors classifier. In this paper all performance metrics will be measured in simple accuracy of the models to get the right answer.
	
	\subsection{Methodology}
	For each of the two datasets, I will train all five algorithms on the training dataset for the first problem, which includes the 32,561 instance. While testing will be done on the second set of 16,281 instances. From there we will compare the training time, performance (accuracy), and hyper parameter tuning performance. While in the second dataset because I do not have a second testing set provided, the experiment will still be the same however I will manually split the dataset into a training, and testing set using a 80/20 split, where 80\% of the data will be used for training, and 20\% for testing.
	
	\section{Experiment}
	
	\subsection{Decision Tree Classifier}
	
	\subsection{K Nearest Neighbors Classifier}
	
	\subsection{Neural Network Classifier}
	
	\subsection{Boosted Decision Tree Classifier}
	
	\subsection{Support Vector Classifier}
	
	\subsection{Results, Analysis, \& Comparison}

	
\end{document}